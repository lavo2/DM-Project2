{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from itertools import combinations\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics import silhouette_score\\nfrom sklearn.preprocessing import StandardScaler\\nimport pandas as pd\\nfrom tqdm import tqdm\\ndf = pd.read_csv(\\'dataset/incident_profile_95.csv\\')\\n\\nselected_features = [\\'avg_age\\', \\'avg_weather_severity\\', \\'fatality_rate\\', \\'severe_injury_rate\\', \\n                     \\'damage_cost_LB\\', \\'speeding_influence\\',\\n           \\'weekend_crash_rate\\',\\'road_defect_crash_rate\\',\\'night_crash_rate\\',\\'avg_responsibility_score\\']\\n\\nbest_score = -1\\nbest_features = None\\nbest_k = None\\n\\n# Store all combinations and their scores\\ncombinations_scores = []\\nfor r in range(4, len(selected_features) + 1):\\n    for combo in tqdm(combinations(selected_features, r), desc=f\\'Feature combinations of size {r}\\'):\\n        X = df[list(combo)]\\n        \\n        #print(f\\'Features: {combo}\\')\\n        # Standardize the features\\n        scaler = StandardScaler()\\n        X_scaled = scaler.fit_transform(X)\\n        \\n        # Test different values of K\\n        for k in range(2, 11):\\n            kmeans = KMeans(n_clusters=k, random_state=42)\\n            kmeans.fit(X_scaled)\\n            score = silhouette_score(X_scaled, kmeans.labels_)\\n            \\n            combinations_scores.append((combo, k, score))\\n    print(\"combo done with size \",r)\\n\\n# Sort combinations by score in descending order\\ncombinations_scores.sort(key=lambda x: x[2], reverse=True)\\n\\n# Print the best combination\\nbest_combo, best_k, best_score = combinations_scores[0]\\nprint(f\\'Best Silhouette Score: {best_score}\\')\\nprint(f\\'Best Feature Set: {best_combo}\\')\\nprint(f\\'Best K: {best_k}\\') '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from itertools import combinations\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv('dataset/incident_profile_95.csv')\n",
    "\n",
    "selected_features = ['avg_age', 'avg_weather_severity', 'fatality_rate', 'severe_injury_rate', \n",
    "                     'damage_cost_LB', 'speeding_influence',\n",
    "           'weekend_crash_rate','road_defect_crash_rate','night_crash_rate','avg_responsibility_score']\n",
    "\n",
    "best_score = -1\n",
    "best_features = None\n",
    "best_k = None\n",
    "\n",
    "# Store all combinations and their scores\n",
    "combinations_scores = []\n",
    "for r in range(4, len(selected_features) + 1):\n",
    "    for combo in tqdm(combinations(selected_features, r), desc=f'Feature combinations of size {r}'):\n",
    "        X = df[list(combo)]\n",
    "        \n",
    "        #print(f'Features: {combo}')\n",
    "        # Standardize the features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Test different values of K\n",
    "        for k in range(2, 11):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(X_scaled)\n",
    "            score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "            \n",
    "            combinations_scores.append((combo, k, score))\n",
    "    print(\"combo done with size \",r)\n",
    "\n",
    "# Sort combinations by score in descending order\n",
    "combinations_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print the best combination\n",
    "best_combo, best_k, best_score = combinations_scores[0]\n",
    "print(f'Best Silhouette Score: {best_score}')\n",
    "print(f'Best Feature Set: {best_combo}')\n",
    "print(f'Best K: {best_k}') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature combinations of size 6: 210it [5:26:56, 93.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Silhouette Score: 0.5449488722710705\n",
      "Best Feature Set: ('avg_weather_severity', 'fatality_rate', 'severe_injury_rate', 'speeding_influence', 'weekend_crash_rate', 'night_crash_rate')\n",
      "Best K: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv('dataset/incident_profile_95.csv')\n",
    "\n",
    "selected_features = ['avg_age', 'avg_weather_severity', 'fatality_rate', 'severe_injury_rate', \n",
    "                     'damage_cost_LB', 'speeding_influence',\n",
    "           'weekend_crash_rate','road_defect_crash_rate','night_crash_rate','avg_responsibility_score']\n",
    "\n",
    "best_score = -1\n",
    "best_features = None\n",
    "best_k = None\n",
    "\n",
    "# Store all combinations and their scores\n",
    "number_of_features = 6\n",
    "combinations_scores = []\n",
    "for combo in tqdm(combinations(selected_features, number_of_features), desc=f'Feature combinations of size {number_of_features}'):\n",
    "    X = df[list(combo)]\n",
    "    \n",
    "    #print(f'Features: {combo}')\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Test different values of K\n",
    "    for k in range(2, 11):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(X_scaled)\n",
    "        score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "        \n",
    "        combinations_scores.append((combo, k, score))\n",
    "\n",
    "# Sort combinations by score in descending order\n",
    "combinations_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print the best combination\n",
    "best_combo, best_k, best_score = combinations_scores[0]\n",
    "print(f'Best Silhouette Score: {best_score}')\n",
    "print(f'Best Feature Set: {best_combo}')\n",
    "print(f'Best K: {best_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_scores_df = pd.DataFrame(combinations_scores, columns=['Features', 'K', 'Score'])\n",
    "combinations_scores_df.to_csv('combinations_scores6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
